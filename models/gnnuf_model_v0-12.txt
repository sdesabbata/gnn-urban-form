python code/gnnuf_train_model_v0_12.py

Seed set to 2674
Run on CUDA

GAEModel(
  (gae): GAE(
    (encoder): SimpleSparseGINEEncoder(
      (onehot_enc): Sequential(
        (0): Linear(in_features=1, out_features=4, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=4, out_features=32, bias=True)
        (3): LeakyReLU(negative_slope=0.01)
        (4): Dropout(p=0.2, inplace=False)
        (5): Linear(in_features=32, out_features=256, bias=True)
      )
      (gineconv_1_lin): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
      (gineconv_1): GINEConv(nn=Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=256, out_features=256, bias=True)
      ))
      (gineconv_2_lin): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=256, out_features=256, bias=True)
      )
      (gineconv_2): GINEConv(nn=Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=256, out_features=256, bias=True)
      ))
      (gineconv_3_lin): Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Dropout(p=0.2, inplace=False)
        (3): Linear(in_features=256, out_features=256, bias=True)
      )
      (gineconv_3): GINEConv(nn=Sequential(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Dropout(p=0.2, inplace=False)
        (3): Linear(in_features=256, out_features=256, bias=True)
      ))
      (post_lin): Sequential(
        (0): Linear(in_features=256, out_features=32, bias=True)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Linear(in_features=32, out_features=2, bias=True)
      )
    )
    (decoder): InnerProductDecoder()
  )
)

GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs

Finding best initial lr:  77%|███████████████████████████████████████████████████████████████████████████████████████▊                          | 77/100 [00:01<00:00, 42.23it/s]
LR finder stopped early after 77 steps due to diverging loss.
Learning rate set to 0.000630957344480193
new_lr=0.000630957344480193

  | Name | Type | Params | Mode 
--------------------------------------
0 | gae  | GAE  | 413 K  | train
--------------------------------------
413 K     Trainable params
0         Non-trainable params
413 K     Total params
1.653     Total estimated model params size (MB)
36        Modules in train mode
0         Modules in eval mode
Epoch 62: 100%|███████████████████████████████████████████████████████████████████████████████████| 245/245 [00:03<00:00, 62.88it/s, v_num=0_1, val_loss=1.050, train_loss=1.050]

Testing DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 87.47it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│         val_loss          │     1.044353723526001     │
└───────────────────────────┴───────────────────────────┘
